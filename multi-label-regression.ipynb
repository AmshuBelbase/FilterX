{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11398771,"sourceType":"datasetVersion","datasetId":7139069}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom transformers import BertTokenizer, BertModel\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\n# Define your target columns\nTARGET_COLS = [\n    'toxicity', \n    'severe_toxicity', \n    'obscene', \n    'threat', \n    'insult', \n    'identity_attack', \n    'sexual_explicit'\n]\n\ndf_test=pd.read_parquet(\"/kaggle/input/civil-comments/test-00000-of-00001.parquet\")\n\ndf_train1=pd.read_parquet(\"/kaggle/input/civil-comments/train-00000-of-00002.parquet\")\ndf_train2=pd.read_parquet(\"/kaggle/input/civil-comments/train-00001-of-00002.parquet\")\n\ndf_val=pd.read_parquet(\"/kaggle/input/civil-comments/validation-00000-of-00001.parquet\")\n\ndf = pd.concat([df_test, df_train1, df_train2, df_val], ignore_index=True)\n\n# Split data\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:17:12.612204Z","iopub.execute_input":"2025-04-14T10:17:12.612953Z","iopub.status.idle":"2025-04-14T10:17:36.869954Z","shell.execute_reply.started":"2025-04-14T10:17:12.612925Z","shell.execute_reply":"2025-04-14T10:17:36.869380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_df = train_df.sample(n=70000, random_state=42)\ntrain_df = sample_df\nsample_df = val_df.sample(n=14000, random_state=42)\nval_df = sample_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:17:41.083107Z","iopub.execute_input":"2025-04-14T10:17:41.084329Z","iopub.status.idle":"2025-04-14T10:17:41.262321Z","shell.execute_reply.started":"2025-04-14T10:17:41.084305Z","shell.execute_reply":"2025-04-14T10:17:41.261587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ToxicityDataset(Dataset):\n    def __init__(self, texts, targets, tokenizer, max_len=128):\n        self.texts = texts\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        targets = self.targets[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        \n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'targets': torch.FloatTensor(targets)\n        }\n\n# Initialize tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Create datasets\ntrain_dataset = ToxicityDataset(\n    train_df['text'].values,\n    train_df[TARGET_COLS].values,\n    tokenizer\n)\n\nval_dataset = ToxicityDataset(\n    val_df['text'].values,\n    val_df[TARGET_COLS].values,\n    tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:17:43.973794Z","iopub.execute_input":"2025-04-14T10:17:43.974095Z","iopub.status.idle":"2025-04-14T10:17:44.687663Z","shell.execute_reply.started":"2025-04-14T10:17:43.974075Z","shell.execute_reply":"2025-04-14T10:17:44.687140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:17:52.732641Z","iopub.execute_input":"2025-04-14T10:17:52.732915Z","iopub.status.idle":"2025-04-14T10:17:52.737298Z","shell.execute_reply.started":"2025-04-14T10:17:52.732895Z","shell.execute_reply":"2025-04-14T10:17:52.736537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install hf_xet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:18:00.593534Z","iopub.execute_input":"2025-04-14T10:18:00.593825Z","iopub.status.idle":"2025-04-14T10:18:06.310538Z","shell.execute_reply.started":"2025-04-14T10:18:00.593799Z","shell.execute_reply":"2025-04-14T10:18:06.309862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ToxicityRegressor(torch.nn.Module):\n    def __init__(self, n_classes):\n        super(ToxicityRegressor, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = torch.nn.Dropout(p=0.2)\n        self.linear = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n        self.sigmoid = torch.nn.Sigmoid()  # Since your targets are between 0-1\n    \n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        pooled_output = outputs.pooler_output\n        output = self.dropout(pooled_output)\n        output = self.linear(output)\n        return self.sigmoid(output)\n\n# model = ToxicityRegressor(len(TARGET_COLS))\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model = model.to(device)\n\n# Initialize model\nmodel = ToxicityRegressor(len(TARGET_COLS))\n\n# Multi-GPU setup\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_gpus = torch.cuda.device_count()\n\nprint(f\"Number of GPUS: {n_gpus}\")\n\nif n_gpus > 1:\n    print(f\"Using {n_gpus} GPUs!\")\n    model = torch.nn.DataParallel(model)\n    \nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:18:08.360247Z","iopub.execute_input":"2025-04-14T10:18:08.360547Z","iopub.status.idle":"2025-04-14T10:18:10.964002Z","shell.execute_reply.started":"2025-04-14T10:18:08.360521Z","shell.execute_reply":"2025-04-14T10:18:10.963451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 1\noptimizer = AdamW(model.parameters(), lr=2e-5)\ncriterion = torch.nn.MSELoss()  # Mean Squared Error loss for regression\n\ndef train_epoch(model, data_loader, optimizer, device):\n    model.train()\n    losses = []\n    \n    for batch in tqdm(data_loader, desc='Training'):\n        optimizer.zero_grad()\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].to(device)\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        loss = criterion(outputs, targets)\n        losses.append(loss.item())\n        \n        loss.backward()\n        optimizer.step()\n    \n    return np.mean(losses)\n\ndef eval_epoch(model, data_loader, device):\n    model.eval()\n    losses = []\n    all_targets = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc='Evaluating'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n            \n            loss = criterion(outputs, targets)\n            losses.append(loss.item())\n            \n            all_targets.extend(targets.cpu().numpy())\n            all_outputs.extend(outputs.cpu().numpy())\n    \n    # Calculate MAE for each target\n    mae_scores = {}\n    all_targets = np.array(all_targets)\n    all_outputs = np.array(all_outputs)\n    \n    for i, col in enumerate(TARGET_COLS):\n        mae_scores[col] = mean_absolute_error(\n            all_targets[:, i], \n            all_outputs[:, i]\n        )\n    \n    return np.mean(losses), mae_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:18:15.609148Z","iopub.execute_input":"2025-04-14T10:18:15.609421Z","iopub.status.idle":"2025-04-14T10:18:15.618872Z","shell.execute_reply.started":"2025-04-14T10:18:15.609402Z","shell.execute_reply":"2025-04-14T10:18:15.618225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_val_loss = float('inf')\nhistory = {'train_loss': [], 'val_loss': [], 'val_mae': []}\n\nfor epoch in range(EPOCHS):\n    print(f'Epoch {epoch + 1}/{EPOCHS}')\n    print('-' * 10)\n    \n    train_loss = train_epoch(model, train_loader, optimizer, device)\n    val_loss, val_mae = eval_epoch(model, val_loader, device)\n    \n    print(f'Train loss: {train_loss:.4f}')\n    print(f'Val loss: {val_loss:.4f}')\n    print('Validation MAE:')\n    for k, v in val_mae.items():\n        print(f'  {k}: {v:.4f}')\n    \n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_loss)\n    history['val_mae'].append(val_mae)\n    \n    if val_loss < best_val_loss:\n        torch.save(model.state_dict(), 'best_model.bin')\n        best_val_loss = val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:18:23.374759Z","iopub.execute_input":"2025-04-14T10:18:23.375289Z","iopub.status.idle":"2025-04-14T10:40:08.104959Z","shell.execute_reply.started":"2025-04-14T10:18:23.375268Z","shell.execute_reply":"2025-04-14T10:40:08.104078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_toxicity(text, model, tokenizer, device, max_len=128):\n    model.eval()\n    \n    encoding = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=max_len,\n        return_token_type_ids=False,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt',\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n    \n    outputs = outputs.cpu().flatten().numpy()\n    return dict(zip(TARGET_COLS, outputs))\n\n# Example usage\nsample_text = \"this is a toxic comment\"\npredictions = predict_toxicity(sample_text, model, tokenizer, device)\n\nprint(\"Toxicity Predictions:\")\nfor k, v in predictions.items():\n    print(f\"{k}: {v:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:40:21.984633Z","iopub.execute_input":"2025-04-14T10:40:21.985419Z","iopub.status.idle":"2025-04-14T10:40:22.083207Z","shell.execute_reply.started":"2025-04-14T10:40:21.985384Z","shell.execute_reply":"2025-04-14T10:40:22.082481Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"SAVE THE MODEL TO REUSE","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport torch\n\n# Create directory if it doesn't exist\nos.makedirs('/kaggle/working/toxicity_model', exist_ok=True)\n\n# 1. Save model weights (handle DataParallel wrapping)\nif isinstance(model, torch.nn.DataParallel):\n    # If using multiple GPUs, get the underlying model\n    torch.save(model.module.state_dict(), '/kaggle/working/toxicity_model/pytorch_model.bin')\n    # Get the config from the underlying BERT model\n    bert_config = model.module.bert.config\nelse:\n    torch.save(model.state_dict(), '/kaggle/working/toxicity_model/pytorch_model.bin')\n    bert_config = model.bert.config\n\n# 2. Save model configuration\nbert_config.save_pretrained('/kaggle/working/toxicity_model')\n\n# 3. Save tokenizer\ntokenizer.save_pretrained('/kaggle/working/toxicity_model')\n\n# 4. Save target columns\nwith open('/kaggle/working/toxicity_model/target_columns.json', 'w') as f:\n    json.dump(TARGET_COLS, f)\n\nprint(\"Model saved successfully in '/kaggle/working/toxicity_model' directory\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:43:01.888196Z","iopub.execute_input":"2025-04-14T10:43:01.888770Z","iopub.status.idle":"2025-04-14T10:43:02.887381Z","shell.execute_reply.started":"2025-04-14T10:43:01.888744Z","shell.execute_reply":"2025-04-14T10:43:02.886631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"LOAD THE MODEL","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig, BertTokenizer\nimport json\nimport torch\n# import pandas as pd\n# import numpy as np\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import mean_absolute_error\nfrom transformers import BertTokenizer, BertModel\n# from torch.optim import AdamW\n# from torch.utils.data import Dataset, DataLoader\n# from tqdm import tqdm\n\nclass ToxicityRegressor(torch.nn.Module):\n    def __init__(self, n_classes):\n        super(ToxicityRegressor, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = torch.nn.Dropout(p=0.2)\n        self.linear = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n        self.sigmoid = torch.nn.Sigmoid()  # Since your targets are between 0-1\n    \n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        pooled_output = outputs.pooler_output\n        output = self.dropout(pooled_output)\n        output = self.linear(output)\n        return self.sigmoid(output)\n\ndef load_toxicity_model(model_dir, device):\n    \"\"\"Load the model from saved files\"\"\"\n    # 1. Load configuration\n    config = BertConfig.from_pretrained(model_dir)\n    \n    # 2. Load tokenizer\n    tokenizer = BertTokenizer.from_pretrained(model_dir)\n    \n    # 3. Load target columns\n    with open(f'{model_dir}/target_columns.json', 'r') as f:\n        target_cols = json.load(f)\n    \n    # 4. Initialize model architecture\n    model = ToxicityRegressor(len(target_cols))\n    \n    # 5. Load weights (map to device if needed)\n    state_dict = torch.load(f'{model_dir}/pytorch_model.bin', map_location=device)\n    model.load_state_dict(state_dict) \n\n    n_gpus = torch.cuda.device_count()\n    print(f\"Number of GPUS: {n_gpus}\")\n    if n_gpus > 1:\n        print(f\"Using {n_gpus} GPUs!\")\n        model = torch.nn.DataParallel(model)\n        \n    model = model.to(device)\n    model.eval()\n    \n    return model, tokenizer, target_cols\n\n# Usage\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel, tokenizer, TARGET_COLS = load_toxicity_model('/kaggle/working/toxicity_model', device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:01:57.191711Z","iopub.execute_input":"2025-04-14T11:01:57.192569Z","iopub.status.idle":"2025-04-14T11:02:00.893934Z","shell.execute_reply.started":"2025-04-14T11:01:57.192534Z","shell.execute_reply":"2025-04-14T11:02:00.893125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_batch(texts, model, tokenizer, device, batch_size=16, max_len=128): \n    model.eval()\n    all_predictions = []\n    \n    # Process in batches\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        \n        # Tokenize batch\n        encoding = tokenizer.batch_encode_plus(\n            batch_texts,\n            add_special_tokens=True,\n            max_length=max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        \n        # Move to device\n        input_ids = encoding['input_ids'].to(device)\n        attention_mask = encoding['attention_mask'].to(device)\n        \n        # Predict\n        with torch.no_grad():\n            outputs = model(input_ids=input_ids, \n                          attention_mask=attention_mask)\n        \n        # Handle output based on model type\n        if isinstance(outputs, torch.Tensor):\n            batch_preds = outputs.cpu().numpy()\n        else:  # DataParallel\n            batch_preds = outputs[0].cpu().numpy()\n        \n        # Convert to list of dicts\n        for pred in batch_preds:\n            all_predictions.append(dict(zip(TARGET_COLS, pred)))\n    \n    return all_predictions\n\n# Example batch usage\ntexts = [\n    \"I love this product!\",\n    \"Go die in a hole, you worthless scum\",\n    \"The weather is nice today\",\n    \"People like you should be exterminated\",\n    \"Citizens of US are very dumb\",\n]\n\nresults = predict_batch(texts, model, tokenizer, device)\n\nfor text, pred in zip(texts, results):\n    print(f\"\\nText: {text[:50]}...\")\n    for metric, score in pred.items():\n        if score > 0.3:  # Only show significant scores\n            print(f\"{metric:>16}: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:02:08.389417Z","iopub.execute_input":"2025-04-14T11:02:08.390030Z","iopub.status.idle":"2025-04-14T11:02:09.562944Z","shell.execute_reply.started":"2025-04-14T11:02:08.390005Z","shell.execute_reply":"2025-04-14T11:02:09.562286Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"SAVE AND LOAD SIMPLER","metadata":{}},{"cell_type":"code","source":"# Saving\nsave_dict = {\n    'state_dict': model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict(),\n    'tokenizer': tokenizer,\n    'target_cols': TARGET_COLS,\n    'config': model.module.bert.config if isinstance(model, torch.nn.DataParallel) else model.bert.config\n}\n\ntorch.save(save_dict, 'toxicity_model_full.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncheckpoint = torch.load('toxicity_model_full.pt', map_location=device)\n\nmodel = ToxicityRegressor(len(checkpoint['target_cols']))\nmodel.load_state_dict(checkpoint['state_dict'])\nmodel.to(device)\ntokenizer = checkpoint['tokenizer']\nTARGET_COLS = checkpoint['target_cols']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_batch(texts, model, tokenizer, device, batch_size=16, max_length=128):\n    # Tokenize all texts\n    inputs = tokenizer(\n        texts,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt',\n        add_special_tokens=True\n    )\n    \n    # Create dataset\n    dataset = torch.utils.data.TensorDataset(\n        inputs['input_ids'],\n        inputs['attention_mask']\n    )\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n    \n    all_scores = []\n    \n    # Predict in batches\n    with torch.no_grad():\n        for batch in dataloader:\n            input_ids, attention_mask = batch\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n            \n            batch_scores = outputs.cpu().numpy()\n            all_scores.extend(batch_scores)\n    \n    # Convert to list of dictionaries\n    results = []\n    for scores in all_scores:\n        results.append({col: score for col, score in zip(TARGET_COLS, scores)})\n    \n    return results\n\n# Example batch usage\ntexts = [\n    \"I love this product!\",\n    \"Go die in a hole, you worthless scum\",\n    \"The weather is nice today\",\n    \"People like you should be exterminated\",\n    \"Citizens of US are very dumb\",\n]\n\nbatch_results = predict_batch(texts, model, tokenizer, device)\n\nfor text, scores in zip(texts, batch_results):\n    print(f\"\\nText: {text}\")\n    for metric, score in scores.items():\n        if score > 0.3:  # Only show significant scores\n            print(f\"{metric:>20}: {score:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rm /kaggle/working/best_model.bin","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:08:42.633302Z","iopub.execute_input":"2025-04-14T11:08:42.634026Z","iopub.status.idle":"2025-04-14T11:08:42.751428Z","shell.execute_reply.started":"2025-04-14T11:08:42.633995Z","shell.execute_reply":"2025-04-14T11:08:42.750717Z"}},"outputs":[],"execution_count":null}]}